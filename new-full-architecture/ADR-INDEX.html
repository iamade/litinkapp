<!DOCTYPE html>
<html>
<head>
<title>ADR-INDEX.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="architecture-decision-records-adrs---litinkai-platform">Architecture Decision Records (ADRs) - LitinkAI Platform</h1>
<p>This document contains all significant architectural decisions made for the LitinkAI platform, following the ADR format proposed by Michael Nygard.</p>
<hr>
<h2 id="table-of-contents">Table of Contents</h2>
<ol>
<li><a href="#adr-001-use-fastapi-as-backend-framework">ADR-001: Use FastAPI as Backend Framework</a></li>
<li><a href="#adr-002-use-supabase-for-database-and-authentication">ADR-002: Use Supabase for Database and Authentication</a></li>
<li><a href="#adr-003-implement-microservices-architecture-with-celery">ADR-003: Implement Microservices Architecture with Celery</a></li>
<li><a href="#adr-004-use-openrouter-for-multi-llm-management">ADR-004: Use OpenRouter for Multi-LLM Management</a></li>
<li><a href="#adr-005-implement-tier-based-model-selection">ADR-005: Implement Tier-Based Model Selection</a></li>
<li><a href="#adr-006-use-circuit-breaker-pattern-for-ai-services">ADR-006: Use Circuit Breaker Pattern for AI Services</a></li>
<li><a href="#adr-007-adopt-react-with-typescript-for-frontend">ADR-007: Adopt React with TypeScript for Frontend</a></li>
<li><a href="#adr-008-use-redis-for-caching-and-message-queuing">ADR-008: Use Redis for Caching and Message Queuing</a></li>
<li><a href="#adr-009-implement-rag-system-with-pgvector">ADR-009: Implement RAG System with pgvector</a></li>
<li><a href="#adr-010-use-stripe-for-payment-processing">ADR-010: Use Stripe for Payment Processing</a></li>
<li><a href="#adr-011-implement-jwt-based-authentication">ADR-011: Implement JWT-Based Authentication</a></li>
<li><a href="#adr-012-use-docker-and-docker-compose-for-deployment">ADR-012: Use Docker and Docker Compose for Deployment</a></li>
<li><a href="#adr-013-implement-real-time-cost-tracking">ADR-013: Implement Real-Time Cost Tracking</a></li>
<li><a href="#adr-014-use-modelslab-for-image-and-video-generation">ADR-014: Use ModelsLab for Image and Video Generation</a></li>
<li><a href="#adr-015-use-elevenlabs-for-audio-synthesis">ADR-015: Use ElevenLabs for Audio Synthesis</a></li>
</ol>
<hr>
<h2 id="adr-001-use-fastapi-as-backend-framework">ADR-001: Use FastAPI as Backend Framework</h2>
<p><strong>Status</strong>: Accepted</p>
<p><strong>Date</strong>: 2024-09-15</p>
<h3 id="context">Context</h3>
<p>We needed a Python web framework for building a REST API that handles:</p>
<ul>
<li>High-throughput async operations</li>
<li>Complex AI/ML integrations</li>
<li>Real-time status updates</li>
<li>File uploads and processing</li>
<li>WebSocket connections (future)</li>
</ul>
<p>Options considered:</p>
<ol>
<li><strong>FastAPI</strong> - Modern, async-first, auto-documentation</li>
<li><strong>Django REST Framework</strong> - Mature, full-featured, but synchronous</li>
<li><strong>Flask</strong> - Lightweight, but requires extensive setup for async</li>
</ol>
<h3 id="decision">Decision</h3>
<p>We will use <strong>FastAPI</strong> as our backend framework.</p>
<h3 id="rationale">Rationale</h3>
<p><strong>Pros</strong>:</p>
<ul>
<li>Native async/await support for handling concurrent AI API calls</li>
<li>Automatic OpenAPI/Swagger documentation generation</li>
<li>Built-in data validation with Pydantic</li>
<li>High performance (on par with Node.js and Go)</li>
<li>Type hints improve code quality and IDE support</li>
<li>Growing community and excellent documentation</li>
<li>Easy integration with Celery for background tasks</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>Smaller ecosystem compared to Django</li>
<li>Less mature than Flask/Django</li>
<li>Fewer built-in features (but this keeps it lightweight)</li>
</ul>
<h3 id="consequences">Consequences</h3>
<p><strong>Positive</strong>:</p>
<ul>
<li>Development velocity increased with auto-validation and documentation</li>
<li>Better performance for AI API calls due to async support</li>
<li>Type safety catches errors early in development</li>
<li>Easy onboarding for new developers with auto-generated API docs</li>
</ul>
<p><strong>Negative</strong>:</p>
<ul>
<li>Need to carefully manage async/sync code boundaries</li>
<li>Some third-party libraries may not support async</li>
<li>Team needs to learn async programming patterns</li>
</ul>
<p><strong>Mitigations</strong>:</p>
<ul>
<li>Use <code>asyncio.to_thread()</code> for CPU-bound operations</li>
<li>Implement proper error handling for async operations</li>
<li>Conduct training sessions on async/await patterns</li>
</ul>
<hr>
<h2 id="adr-002-use-supabase-for-database-and-authentication">ADR-002: Use Supabase for Database and Authentication</h2>
<p><strong>Status</strong>: Accepted</p>
<p><strong>Date</strong>: 2024-09-20</p>
<h3 id="context">Context</h3>
<p>We needed a database solution with:</p>
<ul>
<li>PostgreSQL for structured data</li>
<li>Built-in authentication system</li>
<li>Row-Level Security (RLS)</li>
<li>Real-time subscriptions</li>
<li>Object storage for media files</li>
<li>Scalability for future growth</li>
</ul>
<p>Options considered:</p>
<ol>
<li><strong>Supabase</strong> - PostgreSQL + Auth + Storage + Real-time</li>
<li><strong>Firebase</strong> - Google's BaaS, NoSQL-first</li>
<li><strong>Self-hosted PostgreSQL + Auth0</strong> - Full control, more complexity</li>
</ol>
<h3 id="decision">Decision</h3>
<p>We will use <strong>Supabase</strong> as our backend-as-a-service platform.</p>
<h3 id="rationale">Rationale</h3>
<p><strong>Pros</strong>:</p>
<ul>
<li>PostgreSQL database with full SQL support</li>
<li>Built-in authentication with email, OAuth, magic links</li>
<li>Row-Level Security for data isolation</li>
<li>Storage buckets for images, audio, video</li>
<li>pgvector extension for RAG/embeddings</li>
<li>Real-time subscriptions for live updates</li>
<li>Generous free tier for development</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>Vendor lock-in to Supabase ecosystem</li>
<li>Limited control over infrastructure</li>
<li>May need migration path if we outgrow it</li>
</ul>
<h3 id="consequences">Consequences</h3>
<p><strong>Positive</strong>:</p>
<ul>
<li>Rapid development with pre-built auth system</li>
<li>Reduced infrastructure management overhead</li>
<li>Secure by default with RLS policies</li>
<li>Single platform for database, auth, and storage</li>
<li>Built-in backup and replication</li>
</ul>
<p><strong>Negative</strong>:</p>
<ul>
<li>Must design with potential migration in mind</li>
<li>Limited customization of auth flows</li>
<li>Costs can increase with scale</li>
</ul>
<p><strong>Mitigations</strong>:</p>
<ul>
<li>Use Supabase client libraries through abstraction layer</li>
<li>Document all RLS policies and migration steps</li>
<li>Monitor usage and costs monthly</li>
</ul>
<hr>
<h2 id="adr-003-implement-microservices-architecture-with-celery">ADR-003: Implement Microservices Architecture with Celery</h2>
<p><strong>Status</strong>: Accepted</p>
<p><strong>Date</strong>: 2024-09-25</p>
<h3 id="context">Context</h3>
<p>Our video generation pipeline involves multiple long-running tasks:</p>
<ul>
<li>Script generation (10-30 seconds)</li>
<li>Image generation (30-120 seconds per image)</li>
<li>Audio synthesis (10-60 seconds per scene)</li>
<li>Video generation (60-300 seconds per scene)</li>
<li>Video merging (30-120 seconds)</li>
</ul>
<p>These tasks need to run asynchronously without blocking the API.</p>
<p>Options considered:</p>
<ol>
<li><strong>Celery</strong> - Distributed task queue with Redis</li>
<li><strong>RQ</strong> - Simpler queue, less features</li>
<li><strong>AWS Lambda</strong> - Serverless functions</li>
<li><strong>Background threads</strong> - Simple but not scalable</li>
</ol>
<h3 id="decision">Decision</h3>
<p>We will use <strong>Celery</strong> with Redis as the message broker for asynchronous task processing.</p>
<h3 id="rationale">Rationale</h3>
<p><strong>Pros</strong>:</p>
<ul>
<li>Battle-tested for distributed task processing</li>
<li>Supports task retries, scheduling, and chaining</li>
<li>Flower dashboard for monitoring</li>
<li>Can scale horizontally by adding workers</li>
<li>Supports multiple queues for priority management</li>
<li>Works seamlessly with FastAPI</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>Adds complexity with Redis dependency</li>
<li>Requires careful task design for idempotency</li>
<li>Memory usage can grow with large task payloads</li>
</ul>
<h3 id="consequences">Consequences</h3>
<p><strong>Positive</strong>:</p>
<ul>
<li>API remains responsive during long operations</li>
<li>Tasks can be retried automatically on failure</li>
<li>Easy to scale by adding more workers</li>
<li>Clear separation between API and worker concerns</li>
<li>Can prioritize urgent tasks</li>
</ul>
<p><strong>Negative</strong>:</p>
<ul>
<li>Need to manage worker processes</li>
<li>Debugging distributed tasks is harder</li>
<li>Task serialization requires careful design</li>
</ul>
<p><strong>Mitigations</strong>:</p>
<ul>
<li>Implement comprehensive logging in all tasks</li>
<li>Use task IDs for tracking and debugging</li>
<li>Set up Flower dashboard for monitoring</li>
<li>Implement idempotent tasks with unique IDs</li>
<li>Use Redis Sentinel for high availability</li>
</ul>
<hr>
<h2 id="adr-004-use-openrouter-for-multi-llm-management">ADR-004: Use OpenRouter for Multi-LLM Management</h2>
<p><strong>Status</strong>: Accepted</p>
<p><strong>Date</strong>: 2024-10-01</p>
<h3 id="context">Context</h3>
<p>We need to integrate multiple LLM providers:</p>
<ul>
<li>OpenAI (GPT-4, GPT-3.5)</li>
<li>Anthropic (Claude 3.5, Claude 3)</li>
<li>Meta (Llama models)</li>
<li>DeepSeek</li>
<li>Others</li>
</ul>
<p>Managing API keys, rate limits, and routing is complex.</p>
<p>Options considered:</p>
<ol>
<li><strong>OpenRouter</strong> - Unified API for multiple LLMs</li>
<li><strong>Direct integration</strong> - Call each provider separately</li>
<li><strong>LangChain</strong> - Framework for LLM apps</li>
<li><strong>LiteLLM</strong> - Proxy server for LLMs</li>
</ol>
<h3 id="decision">Decision</h3>
<p>We will use <strong>OpenRouter</strong> as our unified interface to multiple LLM providers.</p>
<h3 id="rationale">Rationale</h3>
<p><strong>Pros</strong>:</p>
<ul>
<li>Single API for 100+ models from multiple providers</li>
<li>Handles rate limiting and fallbacks automatically</li>
<li>Transparent pricing with detailed cost tracking</li>
<li>No need to manage individual API keys</li>
<li>Built-in model routing and load balancing</li>
<li>Credits system simplifies billing</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>Additional layer between us and LLM providers</li>
<li>Slight latency overhead</li>
<li>Dependency on third-party service</li>
<li>May not support newest models immediately</li>
</ul>
<h3 id="consequences">Consequences</h3>
<p><strong>Positive</strong>:</p>
<ul>
<li>Simplified LLM integration code</li>
<li>Easy to switch models based on cost/performance</li>
<li>Reduced vendor lock-in to single provider</li>
<li>Automatic fallback when models are unavailable</li>
<li>Centralized cost tracking</li>
</ul>
<p><strong>Negative</strong>:</p>
<ul>
<li>Must monitor OpenRouter service status</li>
<li>Costs include small markup over direct API</li>
<li>Need backup plan if OpenRouter is down</li>
</ul>
<p><strong>Mitigations</strong>:</p>
<ul>
<li>Keep direct API clients for critical models (OpenAI)</li>
<li>Implement circuit breaker for OpenRouter failures</li>
<li>Monitor OpenRouter status page</li>
<li>Cache frequent requests to reduce API calls</li>
</ul>
<hr>
<h2 id="adr-005-implement-tier-based-model-selection">ADR-005: Implement Tier-Based Model Selection</h2>
<p><strong>Status</strong>: Accepted</p>
<p><strong>Date</strong>: 2024-10-05</p>
<h3 id="context">Context</h3>
<p>We have 5 subscription tiers with different capabilities:</p>
<ul>
<li>Free: Limited features, lowest cost models</li>
<li>Basic: Standard features, mid-tier models</li>
<li>Standard: Advanced features, better models</li>
<li>Premium: Professional features, top models</li>
<li>Professional: Enterprise features, best models</li>
</ul>
<p>We need to balance user experience with operational costs.</p>
<h3 id="decision">Decision</h3>
<p>We will implement <strong>tier-based model selection</strong> where subscription level determines which AI models are used.</p>
<h3 id="rationale">Rationale</h3>
<p><strong>Model Assignments</strong>:</p>
<pre class="hljs"><code><div>FREE: Llama 3.2 3B ($0.06/M tokens)
BASIC: DeepSeek Chat ($0.14/M tokens)
STANDARD: Claude 3 Haiku ($0.80/M tokens)
PREMIUM: GPT-4o ($5.00/M tokens)
PROFESSIONAL: Claude 3.5 Sonnet ($15.00/M tokens)
</div></code></pre>
<p><strong>Pros</strong>:</p>
<ul>
<li>Clear value proposition for upgrades</li>
<li>Cost control through tier restrictions</li>
<li>Predictable operational expenses</li>
<li>Better models incentivize subscriptions</li>
<li>Easy to add new tiers/models</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>Free tier may have poor quality output</li>
<li>Users might game the system</li>
<li>Complexity in model management</li>
</ul>
<h3 id="consequences">Consequences</h3>
<p><strong>Positive</strong>:</p>
<ul>
<li>40-80% profit margins maintained per tier</li>
<li>Users see clear quality improvements when upgrading</li>
<li>Costs scale with revenue</li>
<li>Can offer free tier sustainably</li>
</ul>
<p><strong>Negative</strong>:</p>
<ul>
<li>Free users may have poor experience</li>
<li>Need to monitor quality across tiers</li>
<li>Model pricing changes affect margins</li>
</ul>
<p><strong>Mitigations</strong>:</p>
<ul>
<li>Regularly review model performance vs cost</li>
<li>Implement quality metrics per tier</li>
<li>Provide transparent tier comparison</li>
<li>Allow model overrides for critical operations</li>
</ul>
<hr>
<h2 id="adr-006-use-circuit-breaker-pattern-for-ai-services">ADR-006: Use Circuit Breaker Pattern for AI Services</h2>
<p><strong>Status</strong>: Accepted</p>
<p><strong>Date</strong>: 2024-10-10</p>
<h3 id="context">Context</h3>
<p>AI services can fail or become unavailable:</p>
<ul>
<li>API rate limits exceeded</li>
<li>Model capacity constraints</li>
<li>Network issues</li>
<li>Provider outages</li>
</ul>
<p>We need resilient fallback mechanisms.</p>
<p>Options considered:</p>
<ol>
<li><strong>Circuit Breaker Pattern</strong> - Automatic failure detection and fallback</li>
<li><strong>Simple retries</strong> - Keep trying same model</li>
<li><strong>Manual failover</strong> - Require admin intervention</li>
<li><strong>No fallback</strong> - Just fail the request</li>
</ol>
<h3 id="decision">Decision</h3>
<p>We will implement the <strong>Circuit Breaker Pattern</strong> with automatic model fallback chains.</p>
<h3 id="rationale">Rationale</h3>
<p><strong>Implementation</strong>:</p>
<pre class="hljs"><code><div>Fallback Chains:
PROFESSIONAL: Claude <span class="hljs-number">3.5</span> Sonnet → GPT<span class="hljs-number">-4</span>o → Claude <span class="hljs-number">3</span> Opus
PREMIUM: GPT<span class="hljs-number">-4</span>o → Claude <span class="hljs-number">3.5</span> Sonnet → Claude <span class="hljs-number">3</span> Opus
STANDARD: Claude <span class="hljs-number">3</span> Haiku → GPT<span class="hljs-number">-3.5</span> Turbo → Gemini Pro
BASIC: DeepSeek → Llama <span class="hljs-number">3.1</span> <span class="hljs-number">70</span>B → Mixtral <span class="hljs-number">8</span>x7B
FREE: Llama <span class="hljs-number">3.2</span> <span class="hljs-number">3</span>B → Phi<span class="hljs-number">-3</span> Mini → Gemma <span class="hljs-number">2</span>B
</div></code></pre>
<p><strong>Pros</strong>:</p>
<ul>
<li>Automatic recovery from failures</li>
<li>Users don't see errors for transient issues</li>
<li>Prevents cascading failures</li>
<li>Tracks failure rates per model</li>
<li>Easy to configure per tier</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>More complex error handling</li>
<li>May downgrade quality unexpectedly</li>
<li>Circuit state must be shared across workers</li>
</ul>
<h3 id="consequences">Consequences</h3>
<p><strong>Positive</strong>:</p>
<ul>
<li>99.9% success rate even with provider issues</li>
<li>Reduced support tickets from failed generations</li>
<li>Better user experience</li>
<li>Automatic cost optimization</li>
</ul>
<p><strong>Negative</strong>:</p>
<ul>
<li>Users may get lower tier model without knowing</li>
<li>Debugging failures is more complex</li>
<li>Need to tune circuit breaker thresholds</li>
</ul>
<p><strong>Mitigations</strong>:</p>
<ul>
<li>Log all fallbacks with original model attempted</li>
<li>Alert on high fallback rates</li>
<li>Provide transparency in generation metadata</li>
<li>Set conservative circuit breaker thresholds</li>
</ul>
<hr>
<h2 id="adr-007-adopt-react-with-typescript-for-frontend">ADR-007: Adopt React with TypeScript for Frontend</h2>
<p><strong>Status</strong>: Accepted</p>
<p><strong>Date</strong>: 2024-09-18</p>
<h3 id="context">Context</h3>
<p>We needed a modern frontend framework for a complex, interactive application with:</p>
<ul>
<li>Multiple user modes (Learning, Creator, Entertainment)</li>
<li>Real-time status updates</li>
<li>Rich media previews</li>
<li>Complex state management</li>
</ul>
<p>Options considered:</p>
<ol>
<li><strong>React + TypeScript</strong> - Component-based, type-safe</li>
<li><strong>Vue 3</strong> - Progressive framework, composition API</li>
<li><strong>Svelte</strong> - Compiled framework, less boilerplate</li>
<li><strong>Angular</strong> - Full framework, opinionated</li>
</ol>
<h3 id="decision">Decision</h3>
<p>We will use <strong>React with TypeScript</strong> for the frontend application.</p>
<h3 id="rationale">Rationale</h3>
<p><strong>Pros</strong>:</p>
<ul>
<li>Largest ecosystem of components and libraries</li>
<li>Type safety with TypeScript prevents bugs</li>
<li>Virtual DOM for efficient updates</li>
<li>Hooks API for clean state management</li>
<li>Excellent developer tools and IDE support</li>
<li>Large talent pool for hiring</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>Boilerplate for type definitions</li>
<li>Learning curve for TypeScript</li>
<li>Bundle size can be large</li>
</ul>
<h3 id="consequences">Consequences</h3>
<p><strong>Positive</strong>:</p>
<ul>
<li>Faster development with reusable components</li>
<li>Fewer runtime errors with type checking</li>
<li>Better IDE autocomplete and refactoring</li>
<li>Easier onboarding with familiar framework</li>
</ul>
<p><strong>Negative</strong>:</p>
<ul>
<li>Initial setup complexity</li>
<li>Need build tooling (Vite)</li>
<li>Bundle optimization required</li>
</ul>
<p><strong>Mitigations</strong>:</p>
<ul>
<li>Use Vite for fast builds</li>
<li>Implement code splitting</li>
<li>Use React.lazy for route-based splitting</li>
<li>Configure strict TypeScript settings</li>
</ul>
<hr>
<h2 id="adr-008-use-redis-for-caching-and-message-queuing">ADR-008: Use Redis for Caching and Message Queuing</h2>
<p><strong>Status</strong>: Accepted</p>
<p><strong>Date</strong>: 2024-09-28</p>
<h3 id="context">Context</h3>
<p>We need:</p>
<ul>
<li>Fast caching for frequently accessed data</li>
<li>Message broker for Celery tasks</li>
<li>Session storage</li>
<li>Rate limiting counters</li>
<li>Real-time cost tracking</li>
</ul>
<p>Options considered:</p>
<ol>
<li><strong>Redis</strong> - In-memory data store</li>
<li><strong>Memcached</strong> - Simple cache</li>
<li><strong>RabbitMQ</strong> - Message broker</li>
<li><strong>PostgreSQL</strong> - Database only</li>
</ol>
<h3 id="decision">Decision</h3>
<p>We will use <strong>Redis</strong> for caching, message queuing, and session storage.</p>
<h3 id="rationale">Rationale</h3>
<p><strong>Pros</strong>:</p>
<ul>
<li>Sub-millisecond latency</li>
<li>Supports multiple data structures (strings, hashes, sets, sorted sets)</li>
<li>Pub/Sub for real-time updates</li>
<li>Native Celery support</li>
<li>Persistence options for durability</li>
<li>Horizontal scaling with Redis Cluster</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>Memory-bound (RAM costs)</li>
<li>Single-threaded can be bottleneck</li>
<li>Requires careful memory management</li>
</ul>
<h3 id="consequences">Consequences</h3>
<p><strong>Positive</strong>:</p>
<ul>
<li>Fast API responses with cached data</li>
<li>Efficient task queuing</li>
<li>Real-time features possible with Pub/Sub</li>
<li>Simple rate limiting implementation</li>
</ul>
<p><strong>Negative</strong>:</p>
<ul>
<li>Another service to monitor</li>
<li>Data loss risk if not configured for persistence</li>
<li>Memory usage can grow quickly</li>
</ul>
<p><strong>Mitigations</strong>:</p>
<ul>
<li>Set TTL on all cache keys</li>
<li>Use Redis Sentinel for high availability</li>
<li>Monitor memory usage and set maxmemory policy</li>
<li>Regular backups with RDB/AOF</li>
</ul>
<hr>
<h2 id="adr-009-implement-rag-system-with-pgvector">ADR-009: Implement RAG System with pgvector</h2>
<p><strong>Status</strong>: Accepted</p>
<p><strong>Date</strong>: 2024-10-08</p>
<h3 id="context">Context</h3>
<p>For plot generation and script enhancement, we need context-aware AI that understands:</p>
<ul>
<li>Book content and themes</li>
<li>Character relationships</li>
<li>Previous chapters</li>
<li>Genre conventions</li>
</ul>
<p>Options considered:</p>
<ol>
<li><strong>pgvector in PostgreSQL</strong> - Vector storage in main database</li>
<li><strong>Pinecone</strong> - Managed vector database</li>
<li><strong>Weaviate</strong> - Open-source vector database</li>
<li><strong>Chroma</strong> - Lightweight vector store</li>
</ol>
<h3 id="decision">Decision</h3>
<p>We will use <strong>pgvector extension in PostgreSQL</strong> for vector embeddings and similarity search.</p>
<h3 id="rationale">Rationale</h3>
<p><strong>Pros</strong>:</p>
<ul>
<li>Keeps vectors with relational data (no sync issues)</li>
<li>No additional service to manage</li>
<li>ACID guarantees for consistency</li>
<li>Works with existing Supabase setup</li>
<li>Free (no per-query costs)</li>
<li>Supports HNSW index for fast search</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>Not optimized purely for vectors</li>
<li>May be slower than specialized vector DBs at scale</li>
<li>Limited to PostgreSQL's scaling model</li>
</ul>
<h3 id="consequences">Consequences</h3>
<p><strong>Positive</strong>:</p>
<ul>
<li>Simplified architecture (one database)</li>
<li>Atomic updates of data and embeddings</li>
<li>No embedding sync issues</li>
<li>Cost-effective at current scale</li>
</ul>
<p><strong>Negative</strong>:</p>
<ul>
<li>May need migration if we scale beyond PostgreSQL</li>
<li>Vector search performance may degrade at millions of vectors</li>
</ul>
<p><strong>Mitigations</strong>:</p>
<ul>
<li>Create HNSW indexes on embedding columns</li>
<li>Partition vector tables by book_id</li>
<li>Monitor query performance</li>
<li>Plan migration path to dedicated vector DB</li>
</ul>
<hr>
<h2 id="adr-010-use-stripe-for-payment-processing">ADR-010: Use Stripe for Payment Processing</h2>
<p><strong>Status</strong>: Accepted</p>
<p><strong>Date</strong>: 2024-10-03</p>
<h3 id="context">Context</h3>
<p>We need to handle:</p>
<ul>
<li>Subscription billing (monthly/annual)</li>
<li>Payment method storage</li>
<li>Invoicing and receipts</li>
<li>Tax calculations</li>
<li>Regional pricing</li>
<li>Dunning management</li>
</ul>
<p>Options considered:</p>
<ol>
<li><strong>Stripe</strong> - Full-featured payment platform</li>
<li><strong>PayPal</strong> - Widely recognized</li>
<li><strong>Paddle</strong> - Merchant of record</li>
<li><strong>Chargebee</strong> - Subscription management</li>
</ol>
<h3 id="decision">Decision</h3>
<p>We will use <strong>Stripe</strong> for payment processing and subscription management.</p>
<h3 id="rationale">Rationale</h3>
<p><strong>Pros</strong>:</p>
<ul>
<li>Comprehensive API and SDKs</li>
<li>Excellent documentation</li>
<li>Handles PCI compliance</li>
<li>Built-in subscription management</li>
<li>Automatic tax calculation</li>
<li>Strong fraud prevention</li>
<li>Webhooks for event handling</li>
<li>Supports 135+ currencies</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>2.9% + $0.30 per transaction</li>
<li>Complex API for advanced features</li>
<li>US-focused (less coverage in some countries)</li>
</ul>
<h3 id="consequences">Consequences</h3>
<p><strong>Positive</strong>:</p>
<ul>
<li>PCI compliance handled automatically</li>
<li>Reliable recurring billing</li>
<li>Professional checkout experience</li>
<li>Easy to add payment methods</li>
<li>Good analytics dashboard</li>
</ul>
<p><strong>Negative</strong>:</p>
<ul>
<li>Transaction fees impact margins</li>
<li>Must handle webhook processing</li>
<li>Requires secure implementation</li>
</ul>
<p><strong>Mitigations</strong>:</p>
<ul>
<li>Implement idempotent webhook handlers</li>
<li>Store Stripe IDs for reconciliation</li>
<li>Monitor failed payments proactively</li>
<li>Use Stripe Test Mode for development</li>
</ul>
<hr>
<h2 id="adr-011-implement-jwt-based-authentication">ADR-011: Implement JWT-Based Authentication</h2>
<p><strong>Status</strong>: Accepted</p>
<p><strong>Date</strong>: 2024-09-22</p>
<h3 id="context">Context</h3>
<p>We need secure authentication that:</p>
<ul>
<li>Works with Supabase Auth</li>
<li>Supports API access from frontend</li>
<li>Allows token refresh</li>
<li>Enables stateless authentication</li>
<li>Supports future mobile apps</li>
</ul>
<p>Options considered:</p>
<ol>
<li><strong>JWT Tokens</strong> - Stateless, self-contained</li>
<li><strong>Session Cookies</strong> - Server-side state</li>
<li><strong>OAuth 2.0 only</strong> - Third-party only</li>
<li><strong>API Keys</strong> - Simple but less secure</li>
</ol>
<h3 id="decision">Decision</h3>
<p>We will use <strong>JWT-based authentication</strong> with refresh tokens.</p>
<h3 id="rationale">Rationale</h3>
<p><strong>Implementation</strong>:</p>
<ul>
<li>Access tokens: 1-hour expiry</li>
<li>Refresh tokens: 30-day expiry</li>
<li>Stored in httpOnly cookies for web</li>
<li>Authorization header for API clients</li>
</ul>
<p><strong>Pros</strong>:</p>
<ul>
<li>Stateless (no session storage needed)</li>
<li>Self-contained (contains user claims)</li>
<li>Works across multiple services</li>
<li>Mobile-friendly</li>
<li>Integrates with Supabase Auth</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>Cannot revoke before expiry (without blacklist)</li>
<li>Token size larger than session IDs</li>
<li>Need to handle refresh logic</li>
</ul>
<h3 id="consequences">Consequences</h3>
<p><strong>Positive</strong>:</p>
<ul>
<li>Scalable (no session state to sync)</li>
<li>Fast authentication (no DB lookup)</li>
<li>Works with CDN/edge functions</li>
<li>Easy to add API authentication</li>
</ul>
<p><strong>Negative</strong>:</p>
<ul>
<li>Must implement token refresh flow</li>
<li>Logout requires token blacklist</li>
<li>Token theft risks</li>
</ul>
<p><strong>Mitigations</strong>:</p>
<ul>
<li>Short access token expiry (1 hour)</li>
<li>Store refresh tokens securely</li>
<li>Implement token rotation</li>
<li>Add rate limiting on auth endpoints</li>
<li>Use HTTPS only</li>
</ul>
<hr>
<h2 id="adr-012-use-docker-and-docker-compose-for-deployment">ADR-012: Use Docker and Docker Compose for Deployment</h2>
<p><strong>Status</strong>: Accepted</p>
<p><strong>Date</strong>: 2024-09-30</p>
<h3 id="context">Context</h3>
<p>We need reproducible deployment across:</p>
<ul>
<li>Development environments</li>
<li>Staging environment</li>
<li>Production environment</li>
<li>CI/CD pipelines</li>
</ul>
<p>Options considered:</p>
<ol>
<li><strong>Docker + Docker Compose</strong> - Containerization</li>
<li><strong>Kubernetes</strong> - Container orchestration</li>
<li><strong>Virtual Machines</strong> - Traditional hosting</li>
<li><strong>Serverless</strong> - AWS Lambda, Cloud Functions</li>
</ol>
<h3 id="decision">Decision</h3>
<p>We will use <strong>Docker containers with Docker Compose</strong> for service orchestration.</p>
<h3 id="rationale">Rationale</h3>
<p><strong>Pros</strong>:</p>
<ul>
<li>Consistent environments across dev/staging/prod</li>
<li>Easy to version control with Dockerfile</li>
<li>Isolated dependencies per service</li>
<li>Simple scaling with multiple containers</li>
<li>Fast startup times</li>
<li>Good for microservices</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>Learning curve for Docker</li>
<li>Resource overhead vs bare metal</li>
<li>Networking complexity</li>
</ul>
<h3 id="consequences">Consequences</h3>
<p><strong>Positive</strong>:</p>
<ul>
<li>&quot;Works on my machine&quot; problems eliminated</li>
<li>Easy to onboard new developers</li>
<li>Can run full stack locally</li>
<li>Simple rollback with image tags</li>
<li>CI/CD integration straightforward</li>
</ul>
<p><strong>Negative</strong>:</p>
<ul>
<li>Need to learn Docker best practices</li>
<li>Image size management required</li>
<li>Volume management for data persistence</li>
</ul>
<p><strong>Mitigations</strong>:</p>
<ul>
<li>Use multi-stage builds for smaller images</li>
<li>Implement health checks</li>
<li>Use docker-compose for local development</li>
<li>Document container architecture</li>
<li>Set resource limits</li>
</ul>
<hr>
<h2 id="adr-013-implement-real-time-cost-tracking">ADR-013: Implement Real-Time Cost Tracking</h2>
<p><strong>Status</strong>: Accepted</p>
<p><strong>Date</strong>: 2024-10-12</p>
<h3 id="context">Context</h3>
<p>AI API costs can vary dramatically:</p>
<ul>
<li>GPT-4o: $5/M tokens</li>
<li>Claude 3.5 Sonnet: $15/M tokens</li>
<li>DeepSeek: $0.14/M tokens</li>
</ul>
<p>We need to track costs in real-time to:</p>
<ul>
<li>Prevent overspending</li>
<li>Maintain profit margins (40-80% target)</li>
<li>Alert on anomalies</li>
<li>Optimize model selection</li>
</ul>
<p>Options considered:</p>
<ol>
<li><strong>Real-time tracking with Redis + PostgreSQL</strong></li>
<li><strong>Batch processing</strong> - Daily cost reconciliation</li>
<li><strong>Third-party analytics</strong> - LangSmith, Helicone</li>
<li><strong>No tracking</strong> - Trust estimates</li>
</ol>
<h3 id="decision">Decision</h3>
<p>We will implement <strong>real-time cost tracking</strong> with Redis counters and PostgreSQL logging.</p>
<h3 id="rationale">Rationale</h3>
<p><strong>Architecture</strong>:</p>
<pre class="hljs"><code><div>1. API call made → Calculate cost
2. Update Redis counter (fast)
3. Log to PostgreSQL (durable)
4. Check threshold → Alert if needed
5. Daily aggregation job
</div></code></pre>
<p><strong>Pros</strong>:</p>
<ul>
<li>Immediate visibility into costs</li>
<li>Can prevent runaway spending</li>
<li>Detailed per-user cost attribution</li>
<li>Alerts for threshold breaches</li>
<li>Historical cost analysis</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>Additional complexity in every API call</li>
<li>Redis and PostgreSQL overhead</li>
<li>Need to keep in sync</li>
</ul>
<h3 id="consequences">Consequences</h3>
<p><strong>Positive</strong>:</p>
<ul>
<li>Maintained 40-80% profit margins per tier</li>
<li>Caught cost anomalies in minutes, not days</li>
<li>Data-driven model selection decisions</li>
<li>User-level cost visibility for support</li>
</ul>
<p><strong>Negative</strong>:</p>
<ul>
<li>Slight latency overhead (~5ms per request)</li>
<li>Storage growth in usage_logs table</li>
<li>Need monitoring for tracking system itself</li>
</ul>
<p><strong>Mitigations</strong>:</p>
<ul>
<li>Use Redis atomic operations for speed</li>
<li>Partition usage_logs by month</li>
<li>Archive old cost data</li>
<li>Set up cost tracking alerts</li>
<li>Regular audits of tracking accuracy</li>
</ul>
<hr>
<h2 id="adr-014-use-modelslab-for-image-and-video-generation">ADR-014: Use ModelsLab for Image and Video Generation</h2>
<p><strong>Status</strong>: Accepted</p>
<p><strong>Date</strong>: 2024-10-15</p>
<h3 id="context">Context</h3>
<p>We need to generate:</p>
<ul>
<li>Character images (portrait style)</li>
<li>Scene images (landscape, cinematic)</li>
<li>Scene videos (image-to-video animation)</li>
</ul>
<p>Options considered:</p>
<ol>
<li><strong>ModelsLab</strong> - Multi-model API</li>
<li><strong>Stability AI</strong> - Stable Diffusion only</li>
<li><strong>Replicate</strong> - Many models, pay-per-use</li>
<li><strong>Midjourney</strong> - No API available</li>
<li><strong>DALL-E 3</strong> - OpenAI, expensive</li>
</ol>
<h3 id="decision">Decision</h3>
<p>We will use <strong>ModelsLab API</strong> for image and video generation.</p>
<h3 id="rationale">Rationale</h3>
<p><strong>Pros</strong>:</p>
<ul>
<li>Access to SDXL, Stable Diffusion 3, ControlNet</li>
<li>Image-to-video with Stable Video Diffusion</li>
<li>Lora model support for custom styles</li>
<li>API-based, no infrastructure management</li>
<li>Reasonable pricing ($0.01-0.05 per image)</li>
<li>Fast generation times (10-60 seconds)</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>Quality not as high as Midjourney</li>
<li>Limited control over generation parameters</li>
<li>Dependency on third-party service</li>
<li>Queue times during peak usage</li>
</ul>
<h3 id="consequences">Consequences</h3>
<p><strong>Positive</strong>:</p>
<ul>
<li>Can generate images at scale</li>
<li>Multiple model options for different styles</li>
<li>Video generation from images</li>
<li>Predictable costs per generation</li>
</ul>
<p><strong>Negative</strong>:</p>
<ul>
<li>May need fallback for quality issues</li>
<li>Queue delays impact user experience</li>
<li>Limited control over model versions</li>
</ul>
<p><strong>Mitigations</strong>:</p>
<ul>
<li>Implement retry logic for failures</li>
<li>Cache successful prompts for consistency</li>
<li>Monitor generation quality metrics</li>
<li>Have backup provider ready (Stability AI)</li>
<li>Implement prompt engineering best practices</li>
</ul>
<hr>
<h2 id="adr-015-use-elevenlabs-for-audio-synthesis">ADR-015: Use ElevenLabs for Audio Synthesis</h2>
<p><strong>Status</strong>: Accepted</p>
<p><strong>Date</strong>: 2024-10-18</p>
<h3 id="context">Context</h3>
<p>We need high-quality voice synthesis for:</p>
<ul>
<li>Character dialogue (multiple voices)</li>
<li>Scene narration</li>
<li>Emotional expression</li>
<li>Multiple languages (future)</li>
</ul>
<p>Options considered:</p>
<ol>
<li><strong>ElevenLabs</strong> - AI voice synthesis</li>
<li><strong>Azure Cognitive Services</strong> - Microsoft TTS</li>
<li><strong>Google Cloud Text-to-Speech</strong></li>
<li><strong>AWS Polly</strong> - Amazon TTS</li>
<li><strong>OpenAI TTS</strong> - Simple but limited</li>
</ol>
<h3 id="decision">Decision</h3>
<p>We will use <strong>ElevenLabs</strong> for audio synthesis.</p>
<h3 id="rationale">Rationale</h3>
<p><strong>Pros</strong>:</p>
<ul>
<li>Highest quality natural-sounding voices</li>
<li>Emotional range and expression control</li>
<li>Voice cloning for custom characters</li>
<li>Multiple accents and languages</li>
<li>Reasonable pricing ($0.18/1000 characters)</li>
<li>Stream audio for instant playback</li>
</ul>
<p><strong>Cons</strong>:</p>
<ul>
<li>More expensive than cloud providers</li>
<li>API rate limits on lower tiers</li>
<li>Voice library smaller than Google/Azure</li>
<li>Newer company, less established</li>
</ul>
<h3 id="consequences">Consequences</h3>
<p><strong>Positive</strong>:</p>
<ul>
<li>Professional-quality audio output</li>
<li>Character voices sound distinct and natural</li>
<li>Users report high satisfaction with audio</li>
<li>Easy to add new voices</li>
</ul>
<p><strong>Negative</strong>:</p>
<ul>
<li>Higher costs than alternatives (~3x)</li>
<li>Dependency on single provider</li>
<li>API limits require queue management</li>
</ul>
<p><strong>Mitigations</strong>:</p>
<ul>
<li>Cache generated audio by content hash</li>
<li>Implement fallback to Azure TTS</li>
<li>Monitor API usage and costs</li>
<li>Use voice cloning sparingly (more expensive)</li>
<li>Batch audio generation to optimize costs</li>
</ul>
<hr>
<h2 id="summary-table">Summary Table</h2>
<table>
<thead>
<tr>
<th>ADR</th>
<th>Title</th>
<th>Status</th>
<th>Impact</th>
<th>Date</th>
</tr>
</thead>
<tbody>
<tr>
<td>001</td>
<td>FastAPI Backend</td>
<td>Accepted</td>
<td>High</td>
<td>2024-09-15</td>
</tr>
<tr>
<td>002</td>
<td>Supabase Platform</td>
<td>Accepted</td>
<td>High</td>
<td>2024-09-20</td>
</tr>
<tr>
<td>003</td>
<td>Celery Architecture</td>
<td>Accepted</td>
<td>High</td>
<td>2024-09-25</td>
</tr>
<tr>
<td>004</td>
<td>OpenRouter for LLMs</td>
<td>Accepted</td>
<td>High</td>
<td>2024-10-01</td>
</tr>
<tr>
<td>005</td>
<td>Tier-Based Models</td>
<td>Accepted</td>
<td>High</td>
<td>2024-10-05</td>
</tr>
<tr>
<td>006</td>
<td>Circuit Breaker Pattern</td>
<td>Accepted</td>
<td>Medium</td>
<td>2024-10-10</td>
</tr>
<tr>
<td>007</td>
<td>React + TypeScript</td>
<td>Accepted</td>
<td>High</td>
<td>2024-09-18</td>
</tr>
<tr>
<td>008</td>
<td>Redis Caching</td>
<td>Accepted</td>
<td>Medium</td>
<td>2024-09-28</td>
</tr>
<tr>
<td>009</td>
<td>pgvector RAG</td>
<td>Accepted</td>
<td>Medium</td>
<td>2024-10-08</td>
</tr>
<tr>
<td>010</td>
<td>Stripe Payments</td>
<td>Accepted</td>
<td>High</td>
<td>2024-10-03</td>
</tr>
<tr>
<td>011</td>
<td>JWT Authentication</td>
<td>Accepted</td>
<td>High</td>
<td>2024-09-22</td>
</tr>
<tr>
<td>012</td>
<td>Docker Deployment</td>
<td>Accepted</td>
<td>Medium</td>
<td>2024-09-30</td>
</tr>
<tr>
<td>013</td>
<td>Cost Tracking</td>
<td>Accepted</td>
<td>High</td>
<td>2024-10-12</td>
</tr>
<tr>
<td>014</td>
<td>ModelsLab Images</td>
<td>Accepted</td>
<td>Medium</td>
<td>2024-10-15</td>
</tr>
<tr>
<td>015</td>
<td>ElevenLabs Audio</td>
<td>Accepted</td>
<td>Medium</td>
<td>2024-10-18</td>
</tr>
</tbody>
</table>
<hr>
<h2 id="change-process">Change Process</h2>
<p>When making architectural decisions:</p>
<ol>
<li><strong>Propose</strong>: Create new ADR with context and options</li>
<li><strong>Discuss</strong>: Review with team, consider alternatives</li>
<li><strong>Decide</strong>: Make decision and document rationale</li>
<li><strong>Implement</strong>: Execute the decision</li>
<li><strong>Review</strong>: Evaluate consequences after 30-90 days</li>
</ol>
<h3 id="adr-template">ADR Template</h3>
<pre class="hljs"><code><div><span class="hljs-section">## ADR-XXX: [Title]</span>

<span class="hljs-strong">**Status**</span>: [Proposed | Accepted | Deprecated | Superseded]

<span class="hljs-strong">**Date**</span>: YYYY-MM-DD

<span class="hljs-section">### Context</span>
[What is the issue we're seeing that is motivating this decision or change?]

<span class="hljs-section">### Decision</span>
[What is the change that we're proposing and/or doing?]

<span class="hljs-section">### Rationale</span>
[Why did we choose this option? What are the pros and cons?]

<span class="hljs-section">### Consequences</span>
[What becomes easier or harder as a result of this change?]

<span class="hljs-strong">**Positive**</span>:
<span class="hljs-bullet">-

</span><span class="hljs-strong">**Negative**</span>:
<span class="hljs-bullet">-

</span><span class="hljs-strong">**Mitigations**</span>:
<span class="hljs-bullet">-
</span></div></code></pre>
<hr>
<h2 id="references">References</h2>
<ul>
<li><a href="https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions">Architecture Decision Records by Michael Nygard</a></li>
<li><a href="https://adr.github.io/">ADR GitHub Organization</a></li>
<li><a href="README.md">Main Architecture README</a></li>
</ul>
<hr>
<p><strong>Last Updated</strong>: 2025-11-06<br>
<strong>Version</strong>: 1.0<br>
<strong>Maintained By</strong>: Architecture Team</p>

</body>
</html>
